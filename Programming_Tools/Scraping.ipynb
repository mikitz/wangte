{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPING SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "# FUNCTIONS\n",
    "\n",
    "# Sleep\n",
    "def fSleep(x, y):\n",
    "    # x must be larger than y\n",
    "    time.sleep(random.uniform(x, y))\n",
    "\n",
    "# 5etools Start\n",
    "def startScraping(url):\n",
    "    # VARIABLES\n",
    "\n",
    "    # Buttons\n",
    "    button_filter = '//*[@id=\"filter-search-group\"]/button[1]'\n",
    "    button_all_sources = '/html/body/div[7]/div/div[2]/div[1]/div[1]/div[2]/div[2]/div[2]/button[1]'\n",
    "    button_save_filters = '/html/body/div[7]/div/div[1]/div[2]/div[2]/button[3]'\n",
    "\n",
    "    # Lists\n",
    "    list_parent = '//*[@id=\"listcontainer\"]/div[4]'\n",
    "\n",
    "    # SCRAPING\n",
    "\n",
    "    # Open the webpage\n",
    "\n",
    "    # Instantiate an Options object\n",
    "    option = webdriver.ChromeOptions()\n",
    "    #Remove navigator.webdriver flag\n",
    "    option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    # Change the resolution of the browser\n",
    "    option.add_argument(\"window-size=1920,1080\")\n",
    "    # Adjusting the user agent\n",
    "    option.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\")\n",
    "    #Open Browser\n",
    "    driver = webdriver.Chrome(executable_path='Z:\\\\chromedriver.exe', options=option)\n",
    "    # Open the specfied URL\n",
    "    driver.get(url)\n",
    "    # Sleep to avoid errors\n",
    "    time.sleep(random.uniform(10.0, 15.0))\n",
    "\n",
    "    # Set up the filters\n",
    "\n",
    "    # Open the filter menu\n",
    "    driver.find_element_by_xpath(button_filter).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Set the filter to all sources\n",
    "    driver.find_element_by_xpath(button_all_sources).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Extra filter settings for items\n",
    "    #if type == 'item':\n",
    "        \n",
    "    # Save the filter settings\n",
    "    driver.find_element_by_xpath(button_save_filters).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Print noting success\n",
    "    print('Filters set to all sources')\n",
    "    # Return the driver to work with\n",
    "    return driver, list_parent"
   ]
  },
  {
   "source": [
    "# BACKGROUNDS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filters set to all sources\n",
      "Scraping item 1 of 99\n",
      "Scraping item 2 of 99\n",
      "Scraping item 3 of 99\n",
      "Scraping item 4 of 99\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-efd4f05f03e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Sleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mfSleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# ~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-92ebb3f42f82>\u001b[0m in \u001b[0;36mfSleep\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfSleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# x must be larger than y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# 5etools Start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up a DataFrame\n",
    "dfBackgrounds = pd.DataFrame(columns = ['NAME', 'SOURCE', 'PAGE_NUMBER', 'SKILL_PROFICIENCIES', 'LANGUAGES', 'LANGUAGES_COUNT', 'TOOL_PROFICIENCIES', 'EQUIPMENT', 'PERSONALITY_TRAIT', 'IDEAL', 'BOND', 'FLAW'])\n",
    "\n",
    "# Open 5etools.com and set up the filters\n",
    "driver, list_parent = startScraping(\"https://5e.tools/backgrounds.html#acolyte_phb\")\n",
    "\n",
    "# VARIABLES\n",
    "\n",
    "# Count the number of rows\n",
    "myList = driver.find_element_by_xpath(list_parent)\n",
    "vRowCount = len(myList.find_elements_by_xpath(\"./*\"))\n",
    "\n",
    "# Loop through all the rows and scrape their data\n",
    "for row in range(1, vRowCount + 1):\n",
    "    print(f'Scraping item {row} of {vRowCount}')\n",
    "\n",
    "    # Set up the row based on its index\n",
    "    xRow = f'//*[@id=\"listcontainer\"]/div[4]/div[{row}]'\n",
    "    # Click into the row\n",
    "    driver.find_element_by_xpath(xRow).click()\n",
    "    # Sleep\n",
    "    fSleep(0.5, 1)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # SCRAPING\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # ROW NAME\n",
    "    tName = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[2]').text\n",
    "    workingName = tName.split(\"\\n\")\n",
    "    # Name\n",
    "    finalName = workingName[0]\n",
    "    # Source\n",
    "    finalSource = workingName[1]\n",
    "    # Page Number\n",
    "    finalPageNumber = workingName[2]\n",
    "\n",
    "    # ROW BACKGROUND PROPERTIES\n",
    "    try:\n",
    "        properties = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[4]/td/div/ul').text\n",
    "        properties = properties.split(\"\\n\")\n",
    "        # Define list of properties to look for\n",
    "        propList = ['Skill Proficiencies', 'Languages', 'Equipment', 'Tool Proficiencies']\n",
    "        # Create a dictionary to store the properties\n",
    "        dictProperties = {\"Skill Proficiencies\": '', \"Languages\": '', \"Equipment\": '', \"Tool Proficiencies\": ''}\n",
    "        # Iterate over items in propList\n",
    "        for i in propList:\n",
    "            # Iterate over items in properties\n",
    "            for z in properties:\n",
    "                if i in z:\n",
    "                    prop = z.replace(f'{i} ', \"\")\n",
    "                    # Append to the Dictionary\n",
    "                    dictProperties[i] = prop\n",
    "    except Exception:\n",
    "        # Create a dictionary to store the properties\n",
    "        dictProperties = {\"Skill Proficiencies\": '', \"Languages\": '', \"Equipment\": '', \"Tool Proficiencies\": ''}\n",
    "    \n",
    "    # Extract number of extra languages\n",
    "    if 'One ' in dictProperties['Languages'] or 'one ' in dictProperties['Languages']:\n",
    "        languagesExtra = 1\n",
    "    elif 'Two ' in dictProperties['Languages'] or 'two ' in dictProperties['Languages']:\n",
    "        languagesExtra = 2\n",
    "    elif 'Three ' in dictProperties['Languages'] or 'three ' in dictProperties['Languages']:\n",
    "        languagesExtra = 3\n",
    "    else:\n",
    "        languagesExtra = None\n",
    "    # ROLLING TABLES\n",
    "\n",
    "    # Peronsality Traits\n",
    "    for num in range(2, 6 + 1):\n",
    "        try:\n",
    "            traitsRaw = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[1]/tbody').text\n",
    "            tableTitle = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[1]/thead').text\n",
    "            if 'Trait' in tableTitle:\n",
    "                break\n",
    "        except Exception:\n",
    "            traitsRaw = None\n",
    "    if traitsRaw != None:\n",
    "        traitSplit = traitsRaw.split(\"\\n\")\n",
    "        traitList = []\n",
    "        # Loop through the traitSplit to clean the data\n",
    "        for i in traitSplit:\n",
    "            i = re.sub(\"\\d\\s\", \"\", i)\n",
    "            traitList.append(i)\n",
    "        # Combine into one string to store in the DF\n",
    "        finalTrait = \"-----\".join(traitList)\n",
    "    else:\n",
    "        finalTrait = traitsRaw\n",
    "\n",
    "    # Ideal\n",
    "    for num in range(2, 6 + 1):\n",
    "        try:\n",
    "            idealsRaw = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[2]/tbody').text\n",
    "            tableTitle = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[2]/thead').text\n",
    "            if 'Ideal' in tableTitle:\n",
    "                break\n",
    "        except Exception:\n",
    "            idealsRaw = None\n",
    "    if idealsRaw != None:\n",
    "        idealSplit = idealsRaw.split(\"\\n\")\n",
    "        idealList = []\n",
    "        # Loop through the idealSplit to clean the data\n",
    "        for i in idealSplit:\n",
    "            i = re.sub(\"\\d\\s\", \"\", i)\n",
    "            idealList.append(i)\n",
    "        # Combine into one string to store in the DF\n",
    "        finalIdeal = \"-----\".join(idealList)\n",
    "    else:\n",
    "        finalIdeal = idealsRaw\n",
    "\n",
    "    # Bond\n",
    "    for num in range(2, 6 + 1):\n",
    "        try:\n",
    "            bondsRaw = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[3]/tbody').text\n",
    "            tableTitle = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[3]/thead').text\n",
    "            if 'Bond' in tableTitle:\n",
    "                break\n",
    "        except Exception:\n",
    "            bondsRaw = None\n",
    "    if bondsRaw != None:\n",
    "        bondSplit = bondsRaw.split(\"\\n\")\n",
    "        bondList = []\n",
    "        # Loop through the bondSplit to clean the data\n",
    "        for i in bondSplit:\n",
    "            i = re.sub(\"\\d\\s\", \"\", i)\n",
    "            bondList.append(i)\n",
    "        # Combine into one string to store in the DF\n",
    "        finalBond = \"-----\".join(bondList)\n",
    "    else:\n",
    "        finalBond = bondsRaw\n",
    "\n",
    "    # Flaw\n",
    "    for num in range(2, 6 + 1):\n",
    "        try:\n",
    "            flawsRaw = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[4]/tbody').text\n",
    "            tableTitle = driver.find_element_by_xpath(f'//*[@id=\"pagecontent\"]/tr[4]/td/div/div[{num}]/table[4]/thead').text\n",
    "            if 'Flaw' in tableTitle:\n",
    "                break\n",
    "        except Exception:\n",
    "            flawsRaw = None\n",
    "    if flawsRaw != None:\n",
    "        flawSplit = flawsRaw.split(\"\\n\")\n",
    "        flawList = []\n",
    "        # Loop through the flawSplit to clean the data\n",
    "        for i in flawSplit:\n",
    "            i = re.sub(\"\\d\\s\", \"\", i)\n",
    "            flawList.append(i)\n",
    "        # Combine into one string to store in the DF\n",
    "        finalFlaw = \"-----\".join(flawList)\n",
    "    else:\n",
    "        finalFlaw = flawsRaw\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # DATAFRAME\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    dfBackgrounds = dfBackgrounds.append({'NAME': finalName, 'SOURCE': finalSource, 'PAGE_NUMBER': finalPageNumber, 'SKILL_PROFICIENCIES': dictProperties['Skill Proficiencies'], 'LANGUAGES': dictProperties['Languages'],  'LANGUAGES_COUNT': languagesExtra, 'TOOL_PROFICIENCIES': dictProperties['Tool Proficiencies'], 'EQUIPMENT': dictProperties['Equipment'], 'PERSONALITY_TRAIT': finalTrait, 'IDEAL': finalIdeal, 'BOND': finalBond, 'FLAW': finalFlaw}, ignore_index = True)\n",
    "\n",
    "\n",
    "# Export to XLSX\n",
    "dfBackgrounds.to_excel('backgrounds.xlsx')\n",
    "# Close the driver    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ITEMS"
   ]
  },
  {
   "source": [
    "# "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a DataFrame\r\n",
    "\r\n",
    "# Open 5etools.com and set up the filters for the bestiary\r\n",
    "driver, list_parent = startScraping('https://5e.tools/items.html#battleaxe%20armblade_erlw')\r\n",
    "\r\n",
    "# BASIC VARIABLES\r\n",
    "\r\n",
    "# Mundane table\r\n",
    "tableMundane = '//*[@id=\"listcontainer\"]/div[1]/div[4]'\r\n",
    "# Magic Table\r\n",
    "tableMagic = '//*[@id=\"listcontainer\"]/div[2]/div[3]'\r\n",
    "\r\n",
    "# Count the number of rows in Mundane\r\n",
    "mundaneList = driver.find_element_by_xpath(tableMundane)\r\n",
    "# 367 Mundane Items\r\n",
    "vMundaneCount = len(mundaneList.find_elements_by_xpath(\"./*\"))\r\n",
    "# Print\r\n",
    "print(f'Mundane Items: {vMundaneCount}')\r\n",
    "\r\n",
    "# Count the number of rows in Magic\r\n",
    "magicList = driver.find_element_by_xpath(tableMagic)\r\n",
    "#1014 Magic Items\r\n",
    "vMagicCount = len(magicList.find_elements_by_xpath(\"./*\"))\r\n",
    "# Print\r\n",
    "print(f'Magic Items: {vMagicCount}')\r\n",
    "\r\n",
    "# TABLE VARIABLES\r\n",
    "\r\n",
    "# ROW 2\r\n",
    "row2 = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[2]').text\r\n",
    "workingName = row2.split(\"\\n\")\r\n",
    "# Name\r\n",
    "finalName = workingName[0]\r\n",
    "# Source\r\n",
    "finalSource = workingName[1]\r\n",
    "# Page Number\r\n",
    "finalPageNumber = workingName[2]\r\n",
    "\r\n",
    "# ROW 3\r\n",
    "row3 = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[3]').text\r\n",
    "row3 = row3.split(\" (\")\r\n",
    "rarity = row3[0].split(\", \")\r\n",
    "# Attunement Requirements\r\n",
    "try:\r\n",
    "    finalAttunement = row3[1].replace(\")\", \"\")\r\n",
    "except:\r\n",
    "    pass\r\n",
    "# Rarity Tier\r\n",
    "finalTier = rarity[0]\r\n",
    "# Rarity\r\n",
    "finalRarity = rarity[1]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# ----------------\r\n",
    "# CLOSE THE DRIVER\r\n",
    "# ----------------\r\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BESTIARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a DataFrame\n",
    "\n",
    "# Open 5etools.com and set up the filters for the bestiary\n",
    "driver, list_parent = startScraping('https://5e.tools/bestiary.html#aarakocra_mm')\n",
    "\n",
    "# VARIABLES\n",
    "\n",
    "# Count the number of rows\n",
    "myList = driver.find_element_by_xpath(list_parent)\n",
    "# 1630 Bestiary entries\n",
    "vRowCount = len(myList.find_elements_by_xpath(\"./*\"))\n",
    "# Print\n",
    "print(vRowCount)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPELLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a DataFrame\n",
    "dfSpells = pd.DataFrame(columns = ['NAME', 'SOURCE', 'PAGE_NUMBER', 'LEVEL', 'SCHOOL', 'CASTING_TIME', 'RANGE', 'COMPONENTS', 'COMPONENTS_MATERIALS', 'COMPONENETS_COST', 'DURATION', 'CLASSES', 'SUBCLASSES'])\n",
    "\n",
    "# Open 5etools.com and set up the filters\n",
    "driver, list_parent = startScraping(\"https://5e.tools/spells.html#abi-dalzim's%20horrid%20wilting_xge\")\n",
    "\n",
    "# VARIABLES\n",
    "\n",
    "# Count the number of rows\n",
    "myList = driver.find_element_by_xpath(list_parent)\n",
    "vRowCount = len(myList.find_elements_by_xpath(\"./*\"))\n",
    "# Name\n",
    "xName = '//*[@id=\"pagecontent\"]/tr[2]'\n",
    "# Level & School\n",
    "xLevelSchool = '//*[@id=\"pagecontent\"]/tr[3]'\n",
    "# Casting Time\n",
    "xCastingTime = '//*[@id=\"pagecontent\"]/tr[4]'\n",
    "# Range\n",
    "xRange = '//*[@id=\"pagecontent\"]/tr[5]'\n",
    "# Components\n",
    "xComponents = '//*[@id=\"pagecontent\"]/tr[6]'\n",
    "# Duration\n",
    "xDuration = '//*[@id=\"pagecontent\"]/tr[7]'\n",
    "# Description\n",
    "xDescription = '//*[@id=\"pagecontent\"]/tr[9]'\n",
    "# Classes\n",
    "xClasses = '//*[@id=\"pagecontent\"]/tr[10]/td/div[1]'\n",
    "# Subclasses\n",
    "xSubClasses = '//*[@id=\"pagecontent\"]/tr[10]/td/div[2]'\n",
    "\n",
    "# Loop through all the rows and scrape their data\n",
    "for row in range(1, vRowCount + 1):\n",
    "    print(f'Scraping item {row} of {vRowCount}')\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # SCRAPING\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Set up the row based on its index\n",
    "    xRow = f'//*[@id=\"listcontainer\"]/div[4]/div[{row}]'\n",
    "    # Click into the row\n",
    "    driver.find_element_by_xpath(xRow).click()\n",
    "    # Sleep\n",
    "    fSleep(0.5, 1)\n",
    "\n",
    "    # ROW 2\n",
    "\n",
    "    tName = driver.find_element_by_xpath(xName).text\n",
    "    workingName = tName.split(\"\\n\")\n",
    "    # Name\n",
    "    finalName = workingName[0]\n",
    "    # Source\n",
    "    finalSource = workingName[1]\n",
    "    # Page Number\n",
    "    finalPageNumber = workingName[2]\n",
    "\n",
    "    # ROW 3\n",
    "\n",
    "    tLevelSchool = driver.find_element_by_xpath(xLevelSchool).text\n",
    "    workingLevelSchool = tLevelSchool.split(\" \")\n",
    "    # Level \n",
    "    finalLevel = workingLevelSchool[0]\n",
    "    # School\n",
    "    finalSchool = workingLevelSchool[1]\n",
    "\n",
    "    # ROW 4\n",
    "\n",
    "    tCastingTime = driver.find_element_by_xpath(xCastingTime).text\n",
    "    workingCastingTime = tCastingTime.split(\": \")\n",
    "    # Casting Time\n",
    "    finalCastingTime = workingCastingTime[1]\n",
    "\n",
    "    # ROW 5\n",
    "\n",
    "    tRange = driver.find_element_by_xpath(xRange).text\n",
    "    workingRange = tRange.split(\": \")\n",
    "    # Range\n",
    "    finalRange = workingRange[1]\n",
    "\n",
    "    # Components & Cost\n",
    "    tComponents = driver.find_element_by_xpath(xComponents).text\n",
    "    tComponents = tComponents.replace(\")\", \"\")\n",
    "    workingComponents = tComponents.split(\": \")\n",
    "    workingComponents = workingComponents[1].split(\" (\")\n",
    "    # Components Required\n",
    "    finalComponentsRequired = workingComponents[0]\n",
    "    # Material Components\n",
    "    try:\n",
    "        finalComponentsMaterial = workingComponents[1]\n",
    "    except IndexError:\n",
    "        finalComponentsMaterial = None\n",
    "\n",
    "    # Description\n",
    "    tDescription = driver.find_element_by_xpath(xDescription).text\n",
    "\n",
    "    # Classes\n",
    "    try:\n",
    "        tClasses = driver.find_element_by_xpath(xClasses).text\n",
    "        finalClasses = tClasses.split(\": \")[1]\n",
    "    except:\n",
    "        finalClasses = None\n",
    "\n",
    "    # Subclasses\n",
    "    try:\n",
    "        tSubClasses = driver.find_element_by_xpath(xSubClasses).text\n",
    "        finalSubClasses = tSubClasses.split(\": \")[1]\n",
    "    except:\n",
    "        finalSubClasses = None\n",
    "\n",
    "    # Currency and Cost\n",
    "    try:\n",
    "        # Set up emtpy lists\n",
    "        lCosts = []\n",
    "        lCurrencies = []\n",
    "        # Set up the material description for regex\n",
    "        componentsMaterialsReg = finalComponentsMaterial.replace(\",\", \"\")\n",
    "        # If \"#### gp\" exists in the string\n",
    "        if len(re.findall(\"(\\d+\\s[cesgp]p)\", componentsMaterialsReg)) >= 1:\n",
    "            # Execute the regex\n",
    "            lMatches = re.findall(\"(\\d+\\s[cesgp]p)\", componentsMaterialsReg)\n",
    "            # Set the string\n",
    "            finalCost = ''\n",
    "            # Loop through the matches\n",
    "            for item in lMatches:    \n",
    "                \n",
    "                # DIGITS & CURRENCY\n",
    "\n",
    "                # Pull out the cost\n",
    "                cost = re.search(\"\\d+\", item)[0]\n",
    "                # Append the cost to the cost list\n",
    "                lCosts.append(cost)\n",
    "                # Pull out the currency\n",
    "                currency = item[-2:]\n",
    "                # Append the currency to the currency list\n",
    "                lCurrencies.append(currency)\n",
    "\n",
    "            # Set the matches list to the components cost\n",
    "            finalCost = ', '.join(lMatches)\n",
    "        else:\n",
    "            finalCost = None\n",
    "    except:\n",
    "        finalCost = None\n",
    "\n",
    "    # ROW 7\n",
    "\n",
    "    tDuration = driver.find_element_by_xpath(xDuration).text\n",
    "    workingDuration = tDuration.split(\": \")\n",
    "    # Duration\n",
    "    finalDuration = workingDuration[1]\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # DATAFRAME\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Append the row to the DF\n",
    "    dfSpells = dfSpells.append({'NAME':finalName, 'SOURCE':finalSource, 'PAGE_NUMBER':finalPageNumber, 'LEVEL':finalLevel, 'SCHOOL':finalSchool, 'CASTING_TIME':finalCastingTime, 'RANGE':finalRange, 'COMPONENTS':finalComponentsRequired, 'COMPONENTS_MATERIALS':finalComponentsMaterial, 'COMPONENETS_COST':finalCost, 'DURATION':finalDuration, 'CLASSES': finalClasses, 'SUBCLASSES': finalSubClasses}, ignore_index = True)\n",
    "\n",
    "    # Export to CSV\n",
    "    dfSpells.to_csv('SPELLS.csv')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "orig_nbformat": 3,
  "interpreter": {
   "hash": "6a7100f77c390aa589c4b628fe3b4bf647e9c70ffa35f3e76563f421da5f96cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}