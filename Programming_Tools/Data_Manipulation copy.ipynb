{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPING SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-a07cb8c1da75>, line 65)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-a07cb8c1da75>\"\u001b[1;36m, line \u001b[1;32m65\u001b[0m\n\u001b[1;33m    driver.find_element_by_xpath(button_save_filters).click()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "# FUNCTIONS\n",
    "\n",
    "# Sleep\n",
    "def fSleep(x, y):\n",
    "    # x must be larger than y\n",
    "    time.sleep(random.uniform(x, y))\n",
    "\n",
    "# 5etools Start\n",
    "def startScraping(url, type):\n",
    "    # VARIABLES\n",
    "\n",
    "    # Buttons\n",
    "    button_filter = '//*[@id=\"filter-search-group\"]/button[1]'\n",
    "    button_all_sources = '/html/body/div[7]/div/div[2]/div[1]/div[1]/div[2]/div[2]/div[2]/button[1]'\n",
    "    button_save_filters = '/html/body/div[7]/div/div[1]/div[2]/div[2]/button[3]'\n",
    "\n",
    "    # Lists\n",
    "    list_parent = '//*[@id=\"listcontainer\"]/div[4]'\n",
    "\n",
    "    # SCRAPING\n",
    "\n",
    "    # Open the webpage\n",
    "\n",
    "    # Instantiate an Options object\n",
    "    option = webdriver.ChromeOptions()\n",
    "    #Remove navigator.webdriver flag\n",
    "    option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    # Change the resolution of the browser\n",
    "    option.add_argument(\"window-size=1920,1080\")\n",
    "    # Adjusting the user agent\n",
    "    option.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\")\n",
    "    #Open Browser\n",
    "    driver = webdriver.Chrome(executable_path='chromedriver.exe', options=option)\n",
    "    # Open the specfied URL\n",
    "    driver.get(url)\n",
    "    # Sleep to avoid errors\n",
    "    time.sleep(random.uniform(10.0, 15.0))\n",
    "\n",
    "    # Set up the filters\n",
    "\n",
    "    # Open the filter menu\n",
    "    driver.find_element_by_xpath(button_filter).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Set the filter to all sources\n",
    "    driver.find_element_by_xpath(button_all_sources).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Extra filter settings for items\n",
    "    if type == 'item':\n",
    "        \n",
    "    # Save the filter settings\n",
    "    driver.find_element_by_xpath(button_save_filters).click()\n",
    "    # Sleep to avoid errors\n",
    "    fSleep(3, 5)\n",
    "    # Print noting success\n",
    "    print('Filters set to all sources')\n",
    "    # Return the driver to work with\n",
    "    return driver, list_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ITEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters set to all sources\n",
      "Mundane Items: 367\n",
      "Magic Items: 1014\n"
     ]
    }
   ],
   "source": [
    "# Set up a DataFrame\r\n",
    "\r\n",
    "# Open 5etools.com and set up the filters for the bestiary\r\n",
    "driver, list_parent = startScraping('https://5e.tools/items.html#battleaxe%20armblade_erlw')\r\n",
    "\r\n",
    "# BASIC VARIABLES\r\n",
    "\r\n",
    "# Mundane table\r\n",
    "tableMundane = '//*[@id=\"listcontainer\"]/div[1]/div[4]'\r\n",
    "# Magic Table\r\n",
    "tableMagic = '//*[@id=\"listcontainer\"]/div[2]/div[3]'\r\n",
    "\r\n",
    "# Count the number of rows in Mundane\r\n",
    "mundaneList = driver.find_element_by_xpath(tableMundane)\r\n",
    "# 367 Mundane Items\r\n",
    "vMundaneCount = len(mundaneList.find_elements_by_xpath(\"./*\"))\r\n",
    "# Print\r\n",
    "print(f'Mundane Items: {vMundaneCount}')\r\n",
    "\r\n",
    "# Count the number of rows in Magic\r\n",
    "magicList = driver.find_element_by_xpath(tableMagic)\r\n",
    "#1014 Magic Items\r\n",
    "vMagicCount = len(magicList.find_elements_by_xpath(\"./*\"))\r\n",
    "# Print\r\n",
    "print(f'Magic Items: {vMagicCount}')\r\n",
    "\r\n",
    "# TABLE VARIABLES\r\n",
    "\r\n",
    "# ROW 2\r\n",
    "row2 = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[2]').text\r\n",
    "workingName = row2.split(\"\\n\")\r\n",
    "# Name\r\n",
    "finalName = workingName[0]\r\n",
    "# Source\r\n",
    "finalSource = workingName[1]\r\n",
    "# Page Number\r\n",
    "finalPageNumber = workingName[2]\r\n",
    "\r\n",
    "# ROW 3\r\n",
    "row3 = driver.find_element_by_xpath('//*[@id=\"pagecontent\"]/tr[3]').text\r\n",
    "row3 = row3.split(\" (\")\r\n",
    "rarity = row3[0].split(\", \")\r\n",
    "# Attunement Requirements\r\n",
    "try:\r\n",
    "    finalAttunement = row3[1].replace(\")\", \"\")\r\n",
    "except:\r\n",
    "    pass\r\n",
    "# Rarity Tier\r\n",
    "finalTier = rarity[0]\r\n",
    "# Rarity\r\n",
    "finalRarity = rarity[1]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# ----------------\r\n",
    "# CLOSE THE DRIVER\r\n",
    "# ----------------\r\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'p276'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### For cleaning the list that I copy-paste from 5etools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\r\n",
    "import pandas as pd\r\n",
    "# Read the CSV to a DataFrame\r\n",
    "df = pd.read_csv('RAW DATA/Item Lists by Rarity - Magical Items.csv', header = None)\r\n",
    "# Change the column name\r\n",
    "df.columns = ['stuff']\r\n",
    "# Create a new DataFrame for the final database\r\n",
    "dbMagicItems = pd.DataFrame(columns= ['NAME', 'TYPE', 'WEIGHT', 'ATTUNEMENT', 'RARITY', 'SOURCE', 'LINK'])\r\n",
    "# Set a margin to iterate through the index\r\n",
    "margin = 0\r\n",
    "# Loop through Database's rows and write to them from the CSV\r\n",
    "while margin < len(df):\r\n",
    "    vName = df['stuff'][0 + margin]\r\n",
    "    vType = df['stuff'][1 + margin]\r\n",
    "    vWeight = df['stuff'][2 + margin]    \r\n",
    "    vAttunement = df['stuff'][3 + margin]\r\n",
    "    if vAttunement != 'Ã—':\r\n",
    "        vAttunement = 'N'\r\n",
    "        vRarity = df['stuff'][3 + margin]\r\n",
    "        vSource = df['stuff'][4 + margin]\r\n",
    "        margin += 5\r\n",
    "    else:\r\n",
    "        vAttunement = 'Y'\r\n",
    "        vRarity = df['stuff'][4 + margin]\r\n",
    "        vSource = df['stuff'][5 + margin]\r\n",
    "        margin += 6\r\n",
    "    # Format the name for the link    \r\n",
    "    vNameLink = vName.lower().strip().replace(\" \", \"%20\")\r\n",
    "    vNameLink = vNameLink.replace(\",\", \"%2c\")\r\n",
    "    vNameLink = vNameLink.replace(\"+\", \"%2b\")\r\n",
    "    vNameLink = vNameLink + \"_\" + vSource.lower()\r\n",
    "    # Build the link\r\n",
    "    vLink = f'https://5e.tools/items.html#{vNameLink}'\r\n",
    "    dbMagicItems = dbMagicItems.append({'NAME': vName, 'TYPE': vType, 'WEIGHT': vWeight, 'ATTUNEMENT': vAttunement, 'RARITY': vRarity, 'SOURCE': vSource, 'LINK': vLink}, ignore_index = True)\r\n",
    "# Export to CSV\r\n",
    "dbMagicItems.to_csv('DATA OUTPUT/magic_items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundane (None) Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV into a DataFrame\r\n",
    "dfMundane = pd.read_csv('RAW DATA/Item Lists by Rarity - Mundane Items.csv', header = None)\r\n",
    "# Set the colum name\r\n",
    "dfMundane.columns = ['stuff']\r\n",
    "# Create a new DataFrame for the final database\r\n",
    "dbMundane = pd.DataFrame(columns= ['NAME', 'TYPE', 'COST', 'WEIGHT', 'SOURCE', 'LINK'])\r\n",
    "# Set a margin to iterate through the index\r\n",
    "margin = 0\r\n",
    "# Add rows to the DB while the margin is less than the DF's length\r\n",
    "while margin < len(dfMundane):\r\n",
    "    vName = dfMundane['stuff'][0 + margin]\r\n",
    "    vType = dfMundane['stuff'][1 + margin]\r\n",
    "    vCost = dfMundane['stuff'][2 + margin]\r\n",
    "    vWeight = dfMundane['stuff'][3 + margin]\r\n",
    "    vSource = dfMundane['stuff'][4 + margin]\r\n",
    "    # Format the name for the link    \r\n",
    "    vNameLink = vName.lower().strip().replace(\" \", \"%20\")\r\n",
    "    vNameLink = vNameLink.replace(\",\", \"%2c\")\r\n",
    "    vNameLink = vNameLink.replace(\"+\", \"%2b\")\r\n",
    "    vNameLink = vNameLink + \"_\" + vSource.lower()\r\n",
    "    # Build the link\r\n",
    "    vLink = f'https://5e.tools/items.html#{vNameLink}'\r\n",
    "    # Append a row to the Database\r\n",
    "    dbMundane = dbMundane.append({'NAME': vName, 'TYPE': vType, 'COST': vCost, 'WEIGHT': vWeight, 'SOURCE': vSource, 'LINK': vLink}, ignore_index = True)\r\n",
    "    # Increment the margin\r\n",
    "    margin += 5\r\n",
    "# Export to CSV\r\n",
    "dbMundane.to_csv('DATA OUTPUT/mundane_items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BESTIARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters set to all sources\n"
     ]
    }
   ],
   "source": [
    "# Set up a DataFrame\n",
    "\n",
    "# Open 5etools.com and set up the filters for the bestiary\n",
    "driver, list_parent = startScraping('https://5e.tools/bestiary.html#aarakocra_mm')\n",
    "\n",
    "# VARIABLES\n",
    "\n",
    "# Count the number of rows\n",
    "myList = driver.find_element_by_xpath(list_parent)\n",
    "# 1630 Bestiary entries\n",
    "vRowCount = len(myList.find_elements_by_xpath(\"./*\"))\n",
    "# Print\n",
    "print(vRowCount)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### For cleaning the list that I copy-paste from 5etools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to handle parentheticals, the subtype\r\n",
    "    # E.G. Aberration (shapechanger)\r\n",
    "        # Move the parenthteical to another column named SUBTYPE\r\n",
    "\r\n",
    "# Import necessary modules\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "# Read the CSV to a DataFrame\r\n",
    "df = pd.read_csv('RAW DATA/Bestiary - Sheet1.csv', header = None)\r\n",
    "# Change the column name\r\n",
    "df.columns = ['stuff']\r\n",
    "# Create a new DataFrame for the final database\r\n",
    "dbBestiary = pd.DataFrame(columns= ['NAME', 'TYPE', 'SUBTYPE', 'CR', 'SOURCE', 'LINK'])\r\n",
    "# Set a margin to iterate through the index\r\n",
    "margin = 0\r\n",
    "# Loop through Database's rows and write to them from the CSV\r\n",
    "while margin < len(df):\r\n",
    "    # Get the name\r\n",
    "    vName = df['stuff'][0 + margin]\r\n",
    "    # Get the Type\r\n",
    "    vType = df['stuff'][1 + margin]\r\n",
    "    # Parse the Type into Type and Subtype\r\n",
    "    if '(' in vType:\r\n",
    "        x = re.search('\\s\\(.*\\)', vType)\r\n",
    "        y = x.group(0).strip()\r\n",
    "        vSubtype = re.sub('\\(*\\)*', '', y)\r\n",
    "        vType = re.sub('\\s\\(.*\\)', '', vType)\r\n",
    "    else:\r\n",
    "        vType = vType\r\n",
    "        vSubtype = '' \r\n",
    "    # Get the CR\r\n",
    "    vCR = df['stuff'][2 + margin]\r\n",
    "    # Get the source\r\n",
    "    vSource = df['stuff'][3 + margin]\r\n",
    "    # Format the name for the link    \r\n",
    "    vNameLink = vName.lower().strip().replace(\" \", \"%20\")\r\n",
    "    vNameLink = vNameLink.replace(\",\", \"%2c\")\r\n",
    "    vNameLink = vNameLink.replace(\"+\", \"%2b\")\r\n",
    "    vNameLink = vNameLink + \"_\" + vSource.lower()\r\n",
    "    # Build the link\r\n",
    "    vLink = f'https://5e.tools/bestiary.html#{vNameLink}'\r\n",
    "    dbBestiary = dbBestiary.append({'NAME': vName, 'TYPE': vType, 'SUBTYPE': vSubtype, 'CR': vCR, 'SOURCE': vSource, 'LINK': vLink}, ignore_index = True)\r\n",
    "    # Increment the offset\r\n",
    "    margin += 4\r\n",
    "# Export to CSV\r\n",
    "dbBestiary.to_csv('DATA OUTPUT/bestiary.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPELLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a DataFrame\n",
    "dfSpells = pd.DataFrame(columns = ['NAME', 'SOURCE', 'PAGE_NUMBER', 'LEVEL', 'SCHOOL', 'CASTING_TIME', 'RANGE', 'COMPONENTS', 'COMPONENTS_MATERIALS', 'COMPONENETS_COST', 'DURATION', 'CLASSES', 'SUBCLASSES'])\n",
    "\n",
    "# Open 5etools.com and set up the filters\n",
    "driver, list_parent = startScraping(\"https://5e.tools/spells.html#abi-dalzim's%20horrid%20wilting_xge\")\n",
    "\n",
    "# VARIABLES\n",
    "\n",
    "# Count the number of rows\n",
    "myList = driver.find_element_by_xpath(list_parent)\n",
    "vRowCount = len(myList.find_elements_by_xpath(\"./*\"))\n",
    "# Name\n",
    "xName = '//*[@id=\"pagecontent\"]/tr[2]'\n",
    "# Level & School\n",
    "xLevelSchool = '//*[@id=\"pagecontent\"]/tr[3]'\n",
    "# Casting Time\n",
    "xCastingTime = '//*[@id=\"pagecontent\"]/tr[4]'\n",
    "# Range\n",
    "xRange = '//*[@id=\"pagecontent\"]/tr[5]'\n",
    "# Components\n",
    "xComponents = '//*[@id=\"pagecontent\"]/tr[6]'\n",
    "# Duration\n",
    "xDuration = '//*[@id=\"pagecontent\"]/tr[7]'\n",
    "# Description\n",
    "xDescription = '//*[@id=\"pagecontent\"]/tr[9]'\n",
    "# Classes\n",
    "xClasses = '//*[@id=\"pagecontent\"]/tr[10]/td/div[1]'\n",
    "# Subclasses\n",
    "xSubClasses = '//*[@id=\"pagecontent\"]/tr[10]/td/div[2]'\n",
    "\n",
    "# Loop through all the rows and scrape their data\n",
    "for row in range(1, vRowCount + 1):\n",
    "    print(f'Scraping item {row} of {vRowCount}')\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # SCRAPING\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Set up the row based on its index\n",
    "    xRow = f'//*[@id=\"listcontainer\"]/div[4]/div[{row}]'\n",
    "    # Click into the row\n",
    "    driver.find_element_by_xpath(xRow).click()\n",
    "    # Sleep\n",
    "    fSleep(0.5, 1)\n",
    "\n",
    "    # ROW 2\n",
    "\n",
    "    tName = driver.find_element_by_xpath(xName).text\n",
    "    workingName = tName.split(\"\\n\")\n",
    "    # Name\n",
    "    finalName = workingName[0]\n",
    "    # Source\n",
    "    finalSource = workingName[1]\n",
    "    # Page Number\n",
    "    finalPageNumber = workingName[2]\n",
    "\n",
    "    # ROW 3\n",
    "\n",
    "    tLevelSchool = driver.find_element_by_xpath(xLevelSchool).text\n",
    "    workingLevelSchool = tLevelSchool.split(\" \")\n",
    "    # Level \n",
    "    finalLevel = workingLevelSchool[0]\n",
    "    # School\n",
    "    finalSchool = workingLevelSchool[1]\n",
    "\n",
    "    # ROW 4\n",
    "\n",
    "    tCastingTime = driver.find_element_by_xpath(xCastingTime).text\n",
    "    workingCastingTime = tCastingTime.split(\": \")\n",
    "    # Casting Time\n",
    "    finalCastingTime = workingCastingTime[1]\n",
    "\n",
    "    # ROW 5\n",
    "\n",
    "    tRange = driver.find_element_by_xpath(xRange).text\n",
    "    workingRange = tRange.split(\": \")\n",
    "    # Range\n",
    "    finalRange = workingRange[1]\n",
    "\n",
    "    # Components & Cost\n",
    "    tComponents = driver.find_element_by_xpath(xComponents).text\n",
    "    tComponents = tComponents.replace(\")\", \"\")\n",
    "    workingComponents = tComponents.split(\": \")\n",
    "    workingComponents = workingComponents[1].split(\" (\")\n",
    "    # Components Required\n",
    "    finalComponentsRequired = workingComponents[0]\n",
    "    # Material Components\n",
    "    try:\n",
    "        finalComponentsMaterial = workingComponents[1]\n",
    "    except IndexError:\n",
    "        finalComponentsMaterial = None\n",
    "\n",
    "    # Description\n",
    "    tDescription = driver.find_element_by_xpath(xDescription).text\n",
    "\n",
    "    # Classes\n",
    "    try:\n",
    "        tClasses = driver.find_element_by_xpath(xClasses).text\n",
    "        finalClasses = tClasses.split(\": \")[1]\n",
    "    except:\n",
    "        finalClasses = None\n",
    "\n",
    "    # Subclasses\n",
    "    try:\n",
    "        tSubClasses = driver.find_element_by_xpath(xSubClasses).text\n",
    "        finalSubClasses = tSubClasses.split(\": \")[1]\n",
    "    except:\n",
    "        finalSubClasses = None\n",
    "\n",
    "    # Currency and Cost\n",
    "    try:\n",
    "        # Set up emtpy lists\n",
    "        lCosts = []\n",
    "        lCurrencies = []\n",
    "        # Set up the material description for regex\n",
    "        componentsMaterialsReg = finalComponentsMaterial.replace(\",\", \"\")\n",
    "        # If \"#### gp\" exists in the string\n",
    "        if len(re.findall(\"(\\d+\\s[cesgp]p)\", componentsMaterialsReg)) >= 1:\n",
    "            # Execute the regex\n",
    "            lMatches = re.findall(\"(\\d+\\s[cesgp]p)\", componentsMaterialsReg)\n",
    "            # Set the string\n",
    "            finalCost = ''\n",
    "            # Loop through the matches\n",
    "            for item in lMatches:    \n",
    "                \n",
    "                # DIGITS & CURRENCY\n",
    "\n",
    "                # Pull out the cost\n",
    "                cost = re.search(\"\\d+\", item)[0]\n",
    "                # Append the cost to the cost list\n",
    "                lCosts.append(cost)\n",
    "                # Pull out the currency\n",
    "                currency = item[-2:]\n",
    "                # Append the currency to the currency list\n",
    "                lCurrencies.append(currency)\n",
    "\n",
    "            # Set the matches list to the components cost\n",
    "            finalCost = ', '.join(lMatches)\n",
    "        else:\n",
    "            finalCost = None\n",
    "    except:\n",
    "        finalCost = None\n",
    "\n",
    "    # ROW 7\n",
    "\n",
    "    tDuration = driver.find_element_by_xpath(xDuration).text\n",
    "    workingDuration = tDuration.split(\": \")\n",
    "    # Duration\n",
    "    finalDuration = workingDuration[1]\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # DATAFRAME\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Append the row to the DF\n",
    "    dfSpells = dfSpells.append({'NAME':finalName, 'SOURCE':finalSource, 'PAGE_NUMBER':finalPageNumber, 'LEVEL':finalLevel, 'SCHOOL':finalSchool, 'CASTING_TIME':finalCastingTime, 'RANGE':finalRange, 'COMPONENTS':finalComponentsRequired, 'COMPONENTS_MATERIALS':finalComponentsMaterial, 'COMPONENETS_COST':finalCost, 'DURATION':finalDuration, 'CLASSES': finalClasses, 'SUBCLASSES': finalSubClasses}, ignore_index = True)\n",
    "\n",
    "    # Export to CSV\n",
    "    dfSpells.to_csv('SPELLS.csv')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### For cleaning the list that I copy-paste from 5etools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\r\n",
    "import pandas as pd\r\n",
    "# Read the CSV to a DataFrame\r\n",
    "dfSpells = pd.read_csv('RAW DATA/Spells - Sheet1.csv', header = None)\r\n",
    "# Change the column name\r\n",
    "dfSpells.columns = ['stuff']\r\n",
    "# Create a new DataFrame for the final database\r\n",
    "dbSpells = pd.DataFrame(columns= ['NAME', 'LEVEL', 'RITUAL', 'TECHNOLOGY', 'CASTING_TIME', 'SCHOOL', 'CONCENTRATION', 'RANGE', 'SOURCE', 'LINK'])\r\n",
    "# Set a margin to iterate through the index\r\n",
    "margin = 0\r\n",
    "# Loop through Database's rows and write to them from the CSV\r\n",
    "while margin < len(dfSpells):\r\n",
    "    vName = dfSpells['stuff'][0 + margin]\r\n",
    "    vLevel = dfSpells['stuff'][1 + margin]\r\n",
    "    # Parse the level\r\n",
    "    if '(rit.)' in vLevel:\r\n",
    "        x = re.search('\\s\\(.*\\)', vLevel)\r\n",
    "        y = x.group(0).strip()\r\n",
    "        vRitual = 'Y'\r\n",
    "        vLevel = re.sub('\\s\\(.*\\)', '', vLevel)\r\n",
    "        vTech = 'N'\r\n",
    "    elif '(tec.)' in vLevel:\r\n",
    "        x = re.search('\\s\\(.*\\)', vLevel)\r\n",
    "        y = x.group(0).strip()\r\n",
    "        vTech = 'Y'\r\n",
    "        vLevel = re.sub('\\s\\(.*\\)', '', vLevel)\r\n",
    "        vRitual = 'N'\r\n",
    "    else:\r\n",
    "        vLevel = vLevel\r\n",
    "        vRitual = 'N'\r\n",
    "        vTech = 'N'\r\n",
    "    vCastingTime = dfSpells['stuff'][2 + margin]    \r\n",
    "    vSchool = dfSpells['stuff'][3 + margin]\r\n",
    "    vConcentration = dfSpells['stuff'][4 + margin]\r\n",
    "    if vConcentration != 'Ã—':\r\n",
    "        vConcentration = 'N'\r\n",
    "        vRange = dfSpells['stuff'][4 + margin]\r\n",
    "        vSource = dfSpells['stuff'][5 + margin]\r\n",
    "        margin += 6\r\n",
    "    else:\r\n",
    "        vConcentration = 'Y'\r\n",
    "        vRange = dfSpells['stuff'][5 + margin]\r\n",
    "        vSource = dfSpells['stuff'][6 + margin]\r\n",
    "        margin += 7\r\n",
    "    # Format the name for the link    \r\n",
    "    vNameLink = vName.lower().strip().replace(\" \", \"%20\")\r\n",
    "    vNameLink = vNameLink.replace(\",\", \"%2c\")\r\n",
    "    vNameLink = vNameLink.replace(\"+\", \"%2b\")\r\n",
    "    vNameLink = vNameLink + \"_\" + vSource.lower()\r\n",
    "    # Build the link\r\n",
    "    vLink = f'https://5e.tools/spells.html#{vNameLink}'\r\n",
    "    dbSpells = dbSpells.append({'NAME': vName, 'LEVEL': vLevel, 'RITUAL': vRitual, 'TECHNOLOGY': vTech,'CASTING_TIME': vCastingTime, 'SCHOOL': vSchool, 'CONCENTRATION': vConcentration, 'RANGE': vRange, 'SOURCE': vSource, 'LINK': vLink}, ignore_index = True)\r\n",
    "# Export to CSV\r\n",
    "dbSpells.to_csv('DATA OUTPUT/spells.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd06a7100f77c390aa589c4b628fe3b4bf647e9c70ffa35f3e76563f421da5f96cf",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}